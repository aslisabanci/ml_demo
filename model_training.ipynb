{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with XGBoost on Algorithmia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train, evaluate and test XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data\n",
    "Let's load our training data, take a look at a few rows and one of the review texts in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...      5.0   \n",
       "1  The product does exactly as it should and is q...      5.0   \n",
       "2  The primary job of this device is to block the...      5.0   \n",
       "3  Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4  This pop filter is great. It looks and perform...      5.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>helpful</th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>reviewTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A2IBPI20UZIR0U</td>\n      <td>1384719342</td>\n      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n      <td>[0, 0]</td>\n      <td>Not much to write about here, but it does exac...</td>\n      <td>5.0</td>\n      <td>good</td>\n      <td>1393545600</td>\n      <td>02 28, 2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A14VAT5EAX3D9S</td>\n      <td>1384719342</td>\n      <td>Jake</td>\n      <td>[13, 14]</td>\n      <td>The product does exactly as it should and is q...</td>\n      <td>5.0</td>\n      <td>Jake</td>\n      <td>1363392000</td>\n      <td>03 16, 2013</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A195EZSQDW3E21</td>\n      <td>1384719342</td>\n      <td>Rick Bennette \"Rick Bennette\"</td>\n      <td>[1, 1]</td>\n      <td>The primary job of this device is to block the...</td>\n      <td>5.0</td>\n      <td>It Does The Job Well</td>\n      <td>1377648000</td>\n      <td>08 28, 2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A2C00NNG1ZQQG2</td>\n      <td>1384719342</td>\n      <td>RustyBill \"Sunday Rocker\"</td>\n      <td>[0, 0]</td>\n      <td>Nice windscreen protects my MXL mic and preven...</td>\n      <td>5.0</td>\n      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n      <td>1392336000</td>\n      <td>02 14, 2014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A94QU4C90B1AX</td>\n      <td>1384719342</td>\n      <td>SEAN MASLANKA</td>\n      <td>[0, 0]</td>\n      <td>This pop filter is great. It looks and perform...</td>\n      <td>5.0</td>\n      <td>No more pops when I record my vocals.</td>\n      <td>1392940800</td>\n      <td>02 21, 2014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/amazon_musical_reviews/Musical_instruments_reviews.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data[\"reviewText\"].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Time to process our texts! Basically, we'll:\n",
    "- Remove the English stopwords\n",
    "- Remove punctuations\n",
    "- Drop unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/aslisabanci/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def threshold_ratings(data):\n",
    "    def threshold_overall_rating(rating):\n",
    "        return 0 if int(rating)<=3 else 1\n",
    "    data[\"overall\"] = data[\"overall\"].apply(threshold_overall_rating)\n",
    "\n",
    "def remove_stopwords_punctuation(data):\n",
    "    data[\"review\"] = data[\"reviewText\"] + data[\"summary\"]\n",
    "\n",
    "    puncs = list(punctuation)\n",
    "    stops = stopwords.words(\"english\")\n",
    "\n",
    "    def remove_stopwords_in_str(input_str):\n",
    "        filtered = [char for char in str(input_str).split() if char not in stops]\n",
    "        return ' '.join(filtered)\n",
    "\n",
    "    def remove_punc_in_str(input_str):\n",
    "        filtered = [char for char in input_str if char not in puncs]\n",
    "        return ''.join(filtered)\n",
    "\n",
    "    def remove_stopwords_in_series(input_series):\n",
    "        text_clean = []\n",
    "        for i in range(len(input_series)):\n",
    "            text_clean.append(remove_stopwords_in_str(input_series[i]))\n",
    "        return text_clean\n",
    "\n",
    "    def remove_punc_in_series(input_series):\n",
    "        text_clean = []\n",
    "        for i in range(len(input_series)):\n",
    "            text_clean.append(remove_punc_in_str(input_series[i]))\n",
    "        return text_clean\n",
    "\n",
    "    data[\"review\"] = remove_stopwords_in_series(data[\"review\"].str.lower())\n",
    "    data[\"review\"] = remove_punc_in_series(data[\"review\"].str.lower())\n",
    "\n",
    "def drop_unused_colums(data):\n",
    "    data.drop(['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', 'reviewTime', \"reviewText\", \"summary\"], axis=1, inplace=True)\n",
    "\n",
    "def preprocess_reviews(data):\n",
    "    remove_stopwords_punctuation(data)\n",
    "    threshold_ratings(data)\n",
    "    drop_unused_colums(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   overall                                             review\n",
       "0        1  much write here exactly supposed to filters po...\n",
       "1        1  product exactly quite affordablei realized dou...\n",
       "2        1  primary job device block breath would otherwis...\n",
       "3        1  nice windscreen protects mxl mic prevents pops...\n",
       "4        1  pop filter great looks performs like studio fi..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>much write here exactly supposed to filters po...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>product exactly quite affordablei realized dou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>primary job device block breath would otherwis...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>nice windscreen protects mxl mic prevents pops...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>pop filter great looks performs like studio fi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "preprocess_reviews(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 42\n",
    "X = data[\"review\"]\n",
    "y = data[\"overall\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini randomized search\n",
    "Let's set up a very basic cross-validated randomized search over parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"max_depth\": range(9,12), \"min_child_weight\": range(5,8)}\n",
    "rand_search_cv = RandomizedSearchCV(XGBClassifier(), param_distributions=params, n_iter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to vectorize, transform and fit\n",
    "Time to vectorize our data, transform it and then fit our model to it.\n",
    "To be able to feed the text data as numeric values to our model, we will first convert our texts into a matrix of token counts using a CountVectorizer. Then we will convert the count matrix to a normalized tf-idf (term-frequency times inverse document-frequency) representation. Using this transformer, we will be scaling down the impact of tokens that occur very frequently, because they convey less information to us. On the contrary, we will be scaling up the impact of the tokens that occur in a small fraction of the training data because they are more informative to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('model',\n",
       "                 RandomizedSearchCV(estimator=XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            learning_rate=None,\n",
       "                                                            max_delta_step=None,\n",
       "                                                            max_depth=None,\n",
       "                                                            min_child_weight=None,\n",
       "                                                            missing=nan,\n",
       "                                                            monotone_constraints=None,\n",
       "                                                            n_estimators=100,\n",
       "                                                            n_jobs=None,\n",
       "                                                            num_parallel_tree=None,\n",
       "                                                            random_state=None,\n",
       "                                                            reg_alpha=None,\n",
       "                                                            reg_lambda=None,\n",
       "                                                            scale_pos_weight=None,\n",
       "                                                            subsample=None,\n",
       "                                                            tree_method=None,\n",
       "                                                            validate_parameters=None,\n",
       "                                                            verbosity=None),\n",
       "                                    n_iter=4,\n",
       "                                    param_distributions={'max_depth': range(9, 12),\n",
       "                                                         'min_child_weight': range(5, 8)}))])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model  = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', rand_search_cv)\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy: 89.19\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {round(acc * 100, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save XGBoost model to a file\n",
    "We should save the created model object to a local path. The Github action will then take the model object from this path and upload it to Algorithmia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "joblib.dump(model, \"model.pkl\", compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test our serving (Algorithm) code\n",
    "\n",
    "We will now test our algorithm code, ie. **`auto_deploy_demo.py`** script, by simply executing it with the `%run` macro. The script will begin its execution through our `if __name__ == \"__main__\"` line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/aslisabanci/repos/algorithmia_ci/ml_demo/auto_deploy_demo/model_manifest.json\nCalling algorithm apply() func with input: It was a great purchase\n{'sentiment': 1, 'predicting_model_metadata': {'model_file': './model.pkl', 'origin_repo': 'aslisabanci/ml_demo', 'origin_commit_SHA': 'e970f9cf4fa6f4823ca5e5476dd1b60a1f4d01d8', 'origin_commit_msg': 'Testing demo pushes'}}\n"
     ]
    }
   ],
   "source": [
    "%run auto_deploy_demo/src/auto_deploy_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final checks before committing this notebook\n",
    "\n",
    "- Make sure `auto_deploy_demo.py` file is in good shape to be pushed to Algorithmia.\n",
    "\n",
    "- Make sure Algorithmia API Key is not committed and pushed in any file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}